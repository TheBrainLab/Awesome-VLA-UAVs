# Awesome-VLA-UAVs
A list of research papers and other related resources on Vision-Language-Action/Navigation (VLA/VLN) models for UAVs.

Contributions are welcome! 

## 2025

- **[Review]** UAVs Meet LLMs: Overviews and Perspectives Toward Agentic Low-Altitude Mobility (**Information Fusion 2025.3**)[[paper](https://doi.org/10.1016/j.inffus.2025.103158)][[code](https://github.com/Hub-Tian/UAVs_Meet_LLMs?tab=readme-ov-file)]

- OpenFly: A Comprehensive Platform for Aerial Vision-Language Navigation (**arXiv 2025.7**)[[paper](https://arxiv.org/abs/2502.18041)][[code](https://github.com/SHAILAB-IPEC/OpenFly-Platform)]

- TypeFly: Low-Latency Drone Planning With Large Language Models (**IEEE Transactions on Mobile Computing 2025.9**) [[paper](https://ieeexplore.ieee.org/abstract/document/10970379)][[code](https://github.com/typefly/TypeFly)]

- Towards Realistic UAV Vision-Language Navigation: Platform, Benchmark, and Methodology (**OpenUAV**) (**ICLR 2025**)[[paper](https://openreview.net/forum?id=rUvCIvI4eB)][[code](https://github.com/prince687028/TravelUAV)]

- UAV-Flow Colosseo: A Real-World Benchmark for Flying-on-a-Word UAV Imitation Learning (**arXiv 2025.5**)[[paper](https://arxiv.org/abs/2505.15725)][[code](https://github.com/buaa-colalab/UAV-Flow)]

- UAV-ON: A Benchmark for Open-World Object Goal Navigation with Aerial Agents (**ACM MM Dataset Track 2025**)[[paper](https://arxiv.org/abs/2508.00288)][[code](https://github.com/Kyaren/UAV_ON)]

- AeroDuo: Aerial Duo for UAV-based Vision and Language Navigation (**ACM MM 2025**)[[paper](https://arxiv.org/abs/2508.15232)][[code]]

- CityNav: A Large-Scale Dataset for Real-World Aerial Navigation (**ICCV 2025**)[[paper](https://arxiv.org/abs/2406.14240)][[code](https://water-cookie.github.io/city-nav-proj/)]

- CityNavAgent: Aerial Vision-and-Language Navigation with Hierarchical Semantic Planning and Global Memory (**ACL  2025**)[[paper](https://aclanthology.org/2025.acl-long.1511.pdf)][[code](https://github.com/EmbodiedCity/CityNavAgent.code)]

- VLM-Nav: Mapless UAV-Navigation Using Monocular Vision Driven by Vision-Language Model (**SSRN**)[[paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5231854)][[code](https://gcsarker.github.io/vlmnav/)]

- Learning Fine-Grained Alignment for Aerial Vision-Dialog Navigation (**AAAI 2025**)[[paper](https://ojs.aaai.org/index.php/AAAI/article/view/32758/34913)][[code](https://github.com/yifeisu/FELA)]

- UAV-VLA: Vision-Language-Action System for Large Scale Aerial Mission Generation (**Int. Conf. on Human Robot Interaction, HRI 2025**)[[paper](https://arxiv.org/abs/2501.05014)][[code](https://github.com/sautenich/uav-vla)]

- General-Purpose Aerial Intelligent Agents Empowered by Large Language Models (**arXiv 2025.5**)[[paper](https://arxiv.org/abs/2503.08302)][[code]]

- RAVEN: Resilient Aerial Navigation via Open-Set Semantic Memory and Behavior Adaptation (**arXiv 2025.9** "Best Paper Finalist at IROS 2025 Active Perception Workshop")[[paper](https://arxiv.org/pdf/2509.23563)][[project](https://raven-semantic.github.io/)]


## 2024

- **[Review]** Large Language Models for UAVs: Current State and Pathways to the Future (**IEEE Open Journal of Vehicular Technology 2024.8**) [[paper](https://ieeexplore.ieee.org/document/10643253)][[code]]

- AeroVerse: UAV-Agent Benchmark Suite for Simulating, Pre-training, Finetuning, and Evaluating Aerospace Embodied World Models (**arXiv 2024.8**)[[paper](https://arxiv.org/abs/2408.15511)][[code]]

- TPML: Task Planning for Multi-UAV System with Large Language Models (**2024 IEEE 18th International Conference on Control & Automation (ICCA)**)[[paper](https://ieeexplore.ieee.org/document/10591846)][[code](https://github.com/PengICS/eai_sim)]

- EAI-SIM: An Open-Source Embodied AI Simulation Framework with Large Language Models (**2024 IEEE 18th International Conference on Control & Automation (ICCA)**)[[paper](https://ieeexplore.ieee.org/document/10591865)][[code](https://github.com/PengICS/eai_sim)]

- Aerial Vision-and-Language Navigation via Semantic-Topo-Metric Representation Guided LLM Reasoning (**STMR**) (**Submitted to ICRA 2025**)[[paper](https://arxiv.org/abs/2410.08500v1)][[code]]


## 2023

- AerialVLN: Vision-and-Language Navigation for UAVs (**ICCV 2023**)[[paper](https://arxiv.org/abs/2308.06735)][[code](https://github.com/AirVLN/AirVLN)]


## System1 + System2 Thinking

- Visual Agents as Fast and Slow Thinkers (**ICLR 2025**)[[paper](https://arxiv.org/abs/2408.08862)][[code](https://github.com/GuangyanS/Sys2-LLaVA)]

- Dualformer: Controllable Fast and Slow Thinking by Learning with Randomized Reasoning Traces (**arXiv 2025**)[[paper](https://arxiv.org/abs/2410.09918v1)][[code]]

- Helix: A "System 1, System 2" VLA for Whole Upper Body Control (**figure.ai**) [[link](https://www.figure.ai/news/helix)]

- DriveVLM: The Convergence of Autonomous Driving and Large Vision-Language Models (**Conference on Robot Learning (CoRL) 2024**)[[paper](https://arxiv.org/abs/2402.12289v5)][[project](https://tsinghua-mars-lab.github.io/DriveVLM/)]

- Hi Robot: Open-Ended Instruction Following with Hierarchical Vision-Language-Action Models (**Physical Intelligence (Ï€)**) (**ICML 2025**)[[paper](https://arxiv.org/abs/2502.19417)][[blog](https://www.pi.website/research/hirobot)]

- HiRT: Enhancing Robotic Control with Hierarchical Robot Transformers (**Conference on Robot Learning (CoRL) 2024**)[[paper](https://arxiv.org/abs/2410.05273v3)][[code]]

- GR00T N1: An Open Foundation Model for Generalist Humanoid Robots (**arXiv 2025.3**)[[paper](https://arxiv.org/abs/2503.14734)][[code](https://github.com/NVIDIA/Isaac-GR00T)][[tech](https://developer.nvidia.com/isaac/gr00t)]

- GR00T N1.5: An Improved Open Foundation Model for Generalist Humanoid Robots [[tech](https://research.nvidia.com/labs/gear/gr00t-n1_5/)][[code](https://github.com/NVIDIA/Isaac-GR00T)][[blog](https://learnopencv.com/gr00t-n1_5-explained/)]


## Related Awesome lists

- [Hub-Tian/UAVs_Meet_LLMs](https://github.com/Hub-Tian/UAVs_Meet_LLMs)

- [Jiaaqiliu/Awesome-VLA-Robotics](https://github.com/Jiaaqiliu/Awesome-VLA-Robotics)

- [Sautenich/Awesome-Aerial-Vision-Language-Navigation](https://github.com/Sautenich/Awesome-Aerial-Vision-Language-Navigation)


- [Thinklab-SJTU/Awesome-LLM4AD](https://github.com/Thinklab-SJTU/Awesome-LLM4AD)

- [jonyzhang2023/awesome-embodied-vla-va-vln](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)
